import ipywidgets as widgets
from IPython.display import display, Audio, clear_output
import os
import librosa
import noisereduce as nr
import soundfile as sf
from pathlib import Path
import datetime
import torch
from transformers import pipeline
import numpy as np

# Create directories if they don't exist
UPLOAD_DIR = "original_audio"
PROCESSED_DIR = "preprocessed_audio"
TEXT_DIR = "text_output"
Path(UPLOAD_DIR).mkdir(exist_ok=True)
Path(PROCESSED_DIR).mkdir(exist_ok=True)
Path(TEXT_DIR).mkdir(exist_ok=True)

# Check for GPU and use if available
device = "cuda:0" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# Load Whisper model (small version for efficiency)
pipe = pipeline(
    "automatic-speech-recognition",
    model="openai/whisper-small",
    device=device
)

def process_and_save_audio(input_path, target_sr=16000):
    """Process audio and save with timestamp"""
    # Generate output filename with timestamp
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    input_stem = Path(input_path).stem
    output_filename = f"cleaned_{input_stem}_{timestamp}.wav"
    output_path = Path(PROCESSED_DIR) / output_filename

    # Load and process audio
    audio, sr = librosa.load(input_path, sr=target_sr, mono=True)

    # Noise reduction
    audio = nr.reduce_noise(
        y=audio,
        sr=sr,
        stationary=True,
        prop_decrease=0.9,
        n_fft=512,
        win_length=256,
        hop_length=128
    )
    return_timestamps=True

    # Save as WAV file
    sf.write(output_path, audio, sr, subtype='PCM_16')
    return output_path

def preprocess_audio_for_stt(audio_path, target_sr=16000):
    """Optimized audio preprocessing for speech-to-text"""
    # Load with librosa (optimized resampling)
    audio, sr = librosa.load(audio_path, sr=target_sr, mono=True)

    # Normalize audio
    audio = librosa.util.normalize(audio)

    # Trim silence (optional)
    audio, _ = librosa.effects.trim(audio, top_db=20)

    return audio

def on_upload_change(change):
    if change['type'] == 'change' and change['name'] == 'value':
        clear_output()

        # Get uploaded file info
        file_name = next(iter(change['new'].keys()))
        file_content = change['new'][file_name]['content']

        # Save original file
        original_path = Path(UPLOAD_DIR) / file_name
        with open(original_path, 'wb') as f:
            f.write(file_content)

        # Process and save cleaned audio
        processed_path = process_and_save_audio(original_path)

        # Convert to text
        try:
            # Preprocess audio for STT
            audio_array = preprocess_audio_for_stt(processed_path)

            # Convert to text (assuming English by default)
            text = pipe(audio_array, generate_kwargs={"language": "english"})["text"]

            # Save text output
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            text_filename = f"transcript_{Path(original_path).stem}_{timestamp}.txt"
            text_path = Path(TEXT_DIR) / text_filename
            with open(text_path, 'w', encoding='utf-8') as f:
                f.write(text)

            # Display results
            print("üîä Audio Processing and Transcription Complete")
            print(f"üì• Original file saved to: {original_path.absolute()}")
            print(f"‚ú® Preprocessed file saved to: {processed_path.absolute()}")
            print(f"üìÑ Transcript saved to: {text_path.absolute()}")

            print("\nüéß Processed Audio Preview:")
            display(Audio(filename=str(processed_path)))

            print("\nüóíÔ∏è Extracted Text:")
            print(text)

        except Exception as e:
            print(f"‚ùå Error during transcription: {str(e)}")

# Create upload widget
uploader = widgets.FileUpload(
    accept='.wav,.mp3,.flac,.webm,.ogg,.m4a,.opus',
    multiple=False,
    description='Upload Audio',
    style={'description_width': 'initial'}
)

# Display interface
print("üéôÔ∏è Audio Processing and Speech-to-Text Tool")
print(f"üîä Using Whisper model on {device.upper()}")
print(f"üóÇÔ∏è Original files will be saved in: {Path(UPLOAD_DIR).absolute()}")
print(f"‚ú® Cleaned files will be saved in: {Path(PROCESSED_DIR).absolute()}")
print(f"üìù Transcripts will be saved in: {Path(TEXT_DIR).absolute()}")
print("\n‚¨áÔ∏è Upload an audio file to process and transcribe:")
uploader.observe(on_upload_change, names='value')
display(uploader)
